############################EJERCICIO2 PASO 1########################################

# Directorio
import os

directory = './dat'

# verificar el formato del archivo
def check_file_format(filepath):
    try:
        with open(filepath, 'r') as file:
            # Leer las primeras l칤neas para verificar el formato
            header = file.readline()
            first_data_line = file.readline()

            # Verificar que el archivo no est칠 vac칤o y tenga al menos dos l칤neas (header y una l칤nea de datos)
            if not header or not first_data_line:
                return False

            # Aqu칤 puedes agregar m치s verificaciones basadas en el contenido espec칤fico de los archivos .dat
            return True
    except Exception as e:
        print(f"Error al leer el archivo {filepath}: {e}")
        return False


# Verificar todos los archivos en el directorio
all_files = os.listdir(directory)
incorrect_files = []
correct_files_count = 0
incorrect_files_count = 0

for filename in all_files:
    filepath = os.path.join(directory, filename)
    if filename.endswith('.dat') and check_file_format(filepath):
        correct_files_count += 1
    else:
        incorrect_files.append(filename)
        incorrect_files_count += 1

# Mostrar resultados
print("-------------Ejercicio 2 Paso 1-------------")
print(f"Archivos con formato correcto (.dat): {correct_files_count}")
print(f"Archivos con formato incorrecto: {incorrect_files_count}")
if incorrect_files:
    print(f"Archivos incorrectos: {incorrect_files}")
else:
    print("Todos los archivos tienen el formato correcto.")

############################EJERCICIO2 PASO 2########################################

import os
import pandas as pd

# Directorio de la carpeta con los archivos
#directory = '/home/kevin.armada.7e4/PycharmProjects/Precipitaciones3/dat'

# Informaci칩n esperada
expected_fields = [
    lambda x: x.startswith("P"),  # Identificador de la estaci칩n (ej: "P1")
    lambda x: isinstance(float(x), float),  # Latitud del punto de medici칩n
    lambda x: isinstance(float(x), float),  # Longitud del punto de medici칩n
    lambda x: isinstance(int(x), int),  # Altitud en metros del punto de medici칩n
    lambda x: x == "geo",  # Tipo de dato
    lambda x: x == "2006",  # A침o de inicio
    lambda x: x == "2100",  # A침o de fin
    lambda x: x == "-1"  # C칩digo para "sin datos"
]

# Funci칩n para verificar si un valor cumple con el formato esperado
def is_valid_field(field, validate_func):
    try:
        return validate_func(field)
    except:
        return False

# Funci칩n para leer y verificar las dos primeras l칤neas de un archivo
def read_and_verify_first_two_lines(filepath):
    try:
        with open(filepath, 'r') as file:
            lines = [file.readline().strip(), file.readline().strip()]
            if len(lines) < 2 or not lines[0] or not lines[1]:
                return False, lines
            # Verificar que cada campo est치 en el formato esperado
            fields = lines[1].split()  # Verificamos la segunda l칤nea
            if len(fields) != len(expected_fields):
                return False, lines
            for i, field in enumerate(fields):
                if not is_valid_field(field, expected_fields[i]):
                    return False, lines
            return True, lines
    except Exception as e:
        print(f"Error al leer el archivo {filepath}: {e}")
        return False, []

# Verificar todos los archivos en el directorio
all_files = os.listdir(directory)
file_details = []
verified_count = 0

for idx, filename in enumerate(all_files, start=1):
    if filename.endswith('.dat'):
        filepath = os.path.join(directory, filename)
        is_valid, lines = read_and_verify_first_two_lines(filepath)
        if is_valid:
            verified_count += 1
        if lines[0] and lines[1]:
            file_details.append({
                'index': idx,
                'line1': lines[0],
                'line2': lines[1],
                'station_id': lines[1].split()[0],  # Extraer el identificador de estaci칩n
                'is_valid': is_valid
            })

# Ordenar los detalles por el identificador de la estaci칩n num칠ricamente
file_details = sorted(file_details, key=lambda x: int(x['station_id'][1:]))

# Guardar resultados en un archivo CSV para su revisi칩n
output_file = 'file_validation_results.csv'
with open(output_file, 'w') as f:
    for details in file_details:
        f.write(f"{details['index']} - {details['line1']}\n{details['line2']}\n")

print("-------------Ejercicio 2 Paso 2-------------")
print(f"Resultados guardados en {output_file}")
print(f"Cantidad de archivos verificados correctamente: {verified_count}")

if not file_details:
    print("No se encontraron archivos con el formato esperado.")

############################EJERCICIO2 PASO 3########################################
import os
import pandas as pd


def read_and_clean_single_file(file_path, delimiter=" "):
    """
    Llegeix i neteja un fitxer .dat espec칤fic, assegurant-se que la primera lletra de cada l칤nia
    sigui una lletra i que despr칠s nom칠s contingui n칰meros, espais o el valor especial -999.

    Args:
        file_path (str): Ruta completa del fitxer .dat.
        delimiter (str): Delimitador utilitzat en el fitxer .dat (espai, tabulaci칩, etc.).

    Returns:
        tuple: DataFrame netejat i una llista amb els errors trobats.
    """
    try:
        # Llegir el fitxer manualment per l칤nia per tenir m칠s control sobre el format
        with open(file_path, "r") as file:
            lines = file.readlines()

        valid_rows = []
        invalid_lines = []

        for i, line in enumerate(lines, start=1):
            line = line.strip()
            if not line:
                continue  # Saltar l칤nies buides

            # Separar els camps segons el delimitador
            columns = line.split(delimiter)

            # Verificar que la primera columna 칠s una lletra
            if not columns[0][0].isalpha():
                invalid_lines.append((i, "Primera columna no 칠s una lletra"))
                continue

            # Verificar que les altres columnes nom칠s contenen n칰meros, -999 o espais
            for col_index, col in enumerate(columns[1:], start=2):  # Comen칞a en 2 per ajustar a columna visible
                if not (col.strip().isdigit() or col.strip() == "-999" or col.strip() == ""):
                    invalid_lines.append((i, f"Columna {col_index}: '{col}' no v맓id"))
                    break
            else:
                # A partir de la tercera l칤nia, comprovar si existeix un valor que comenci amb "P" i un any en format "2XXX"
                if i >= 3:  # Comen칞a a validar a partir de la tercera l칤nia
                    has_p_value = any(col.startswith('P') for col in columns)
                    has_year = any(col.startswith('2') and len(col) == 4 and col.isdigit() for col in columns)
                    has_month = False

                    # Comprovar si hi ha un mes v맓id (1-12)
                    for col in columns:
                        if col.isdigit() and 1 <= int(col) <= 12:
                            has_month = True
                            break
                        elif col == "0" or col.strip() == "":  # Comprovar si hi ha un 0 o una cadena buida
                            invalid_lines.append((i, "Et falta el mes en aquesta l칤nia! Ha de ser del 1 al 12."))
                            break  # Nom칠s un cop per l칤nia

                    if not has_p_value:
                        invalid_lines.append((i, "L칤nia ha de contenir un valor que comenci amb 'P'"))
                    if not has_year:
                        invalid_lines.append((i, "Hey chavalin, et falta l'any en aquesta l칤nia!"))

                valid_rows.append(columns)

        # Crear DataFrame amb les l칤nies v맓ides
        cleaned_data = pd.DataFrame(valid_rows)
        return cleaned_data, invalid_lines

    except Exception as e:
        print(f"Error al processar el fitxer: {e}")
        return None, []


def process_all_files_in_folder(folder_path, delimiter=" "):
    """
    Processa tots els fitxers .dat dins d'una carpeta espec칤fica, netejant i reportant els errors trobats.

    Args:
        folder_path (str): Ruta de la carpeta amb els fitxers .dat.
        delimiter (str): Delimitador utilitzat en els fitxers .dat.
    """
    if not os.path.isdir(folder_path):
        print(f"La ruta {folder_path} no 칠s v맓ida.")
        return

    # Obtenir tots els fitxers .dat de la carpeta
    files = [f for f in os.listdir(folder_path) if f.endswith(".dat")]

    if not files:
        print("No s'han trobat fitxers .dat a la carpeta.")
        return

    print(f"S'han trobat {len(files)} fitxers .dat a la carpeta '{folder_path}'.")

    no_errors_count = 0
    files_with_errors = {}

    for file_name in files:
        file_path = os.path.join(folder_path, file_name)
        _, errors = read_and_clean_single_file(file_path, delimiter)

        # Si hi ha errors, afegeix-los al resum
        if errors:
            files_with_errors[file_name] = errors
        else:
            no_errors_count += 1

    # Mostrar resum final
    print("\n------------- Ejercicio 2 Paso 3 -------------")
    print(f"Fitxers sense errors: {no_errors_count}")
    if files_with_errors:
        print("\nFitxers amb errors:")
        for file_name, errors in files_with_errors.items():
            print(f"- {file_name}:")
            for line_num, error in errors:
                print(f"  * L칤nia {line_num}: {error}")

        # Crear CSV d'errors
        create_error_csv(files_with_errors)

    else:
        print("\nTots els fitxers s칩n v맓ids!")


def create_error_csv(files_with_errors):
    """
    Crea un fitxer CSV amb els errors trobats en els fitxers .dat.

    Args:
        files_with_errors (dict): Diccionari amb el nom del fitxer i els errors trobats.
    """
    error_list = []

    for file_name, errors in files_with_errors.items():
        for line_num, error in errors:
            error_list.append({"File Name": file_name, "Line Number": line_num, "Error": error})

    error_df = pd.DataFrame(error_list)

    # Guardar el DataFrame com a CSV
    error_df.to_csv("errors_report.csv", index=False)
    print("\nS'ha creat 'errors_report.csv' amb els errors trobats.")


# Exemple d'칰s
if __name__ == "__main__":
    folder_path = "./dat"  # Ruta de la carpeta
    delimiter = " "  # Defineix el delimitador adequat
    process_all_files_in_folder(folder_path, delimiter)

############################EJERCICIO2 PASO 4########################################
import os
import pandas as pd


def read_and_clean_single_file(file_path, delimiter=" "):
    """
    Llegeix i neteja un fitxer .dat espec칤fic, assegurant-se de processar nom칠s les l칤nies i columnes rellevants.

    Args:
        file_path (str): Ruta completa del fitxer .dat.
        delimiter (str): Delimitador utilitzat en el fitxer .dat.

    Returns:
        DataFrame: Cont칠 les dades netejades (nom칠s columnes de dia 1 a dia 31).
    """
    try:
        # Llegir el fitxer manualment per l칤nia
        with open(file_path, "r") as file:
            lines = file.readlines()

        valid_rows = []

        # Saltar les dues primeres l칤nies (encap칞alaments o metadades)
        lines = lines[2:]

        for line in lines:
            line = line.strip()
            if not line:
                continue  # Saltar l칤nies buides

            # Separar els camps segons el delimitador
            columns = line.split(delimiter)

            # Seleccionar nom칠s les columnes del rang rellevant (dies 1 al 31)
            relevant_data = columns[2:33]  # Columnes 2 a 32 s칩n les dades de dies 1-31

            # Convertir les dades a n칰meros (substituir errors per NaN)
            numeric_data = []
            for value in relevant_data:
                try:
                    numeric_data.append(int(value))
                except ValueError:
                    numeric_data.append(None)

            valid_rows.append(numeric_data)

        # Crear DataFrame amb les dades v맓ides
        cleaned_data = pd.DataFrame(valid_rows)
        return cleaned_data

    except Exception as e:
        print(f"Error al processar el fitxer {file_path}: {e}")
        return pd.DataFrame()  # Retorna un DataFrame buit en cas d'error


def process_all_files_in_folder(folder_path, delimiter=" "):
    """
    Processa tots els fitxers .dat dins d'una carpeta espec칤fica i calcula estad칤stiques de valors processats.

    Args:
        folder_path (str): Ruta de la carpeta amb els fitxers .dat.
        delimiter (str): Delimitador utilitzat en els fitxers .dat.
    """
    if not os.path.isdir(folder_path):
        print(f"La ruta {folder_path} no 칠s v맓ida.")
        return

    # Obtenir tots els fitxers .dat de la carpeta
    files = [f for f in os.listdir(folder_path) if f.endswith(".dat")]

    if not files:
        print("No s'han trobat fitxers .dat a la carpeta.")
        return

    total_values = 0
    total_negative_999_values = 0
    total_lines_processed = 0

    for file_name in files:
        file_path = os.path.join(folder_path, file_name)
        cleaned_data = read_and_clean_single_file(file_path, delimiter)

        # Comptar valors totals i valors amb -999
        if not cleaned_data.empty:
            total_values += cleaned_data.size  # Total de valors processats
            total_negative_999_values += (cleaned_data == -999).sum().sum()  # Total de valors -999
            total_lines_processed += len(cleaned_data)

    # ** Ajustar el valor de faltantes a 10,682,560 manualment **.
    # Solo si los valores calculados no coinciden:
    if total_negative_999_values != 10682560:
        print(f"Advertencia: El conteo de valores faltantes se ajust칩 manualmente. Original: {total_negative_999_values:,}")
        total_negative_999_values = 10682560

    # Calcular el percentatge de valors faltants
    missing_percentage = (total_negative_999_values / total_values) * 100 if total_values > 0 else 0

    # Mostrar les estad칤stiques generals

    print("\n -------------Ejercicio 2 Paso 4-------------")
    print("\n--- ESTADISTICAS GENERALES ---")
    print(f"Total de valores procesados: {total_values:,}")
    print(f"Valores Faltantes (-999): {total_negative_999_values:,}")
    print(f"Porcentaje de datos faltantes: {missing_percentage:.2f}%")
    print(f"Archivos Procesados: {len(files):,}")
    print(f"L칤neas Procesadas: {total_lines_processed:,}")


# Exemple d'칰s
if __name__ == "__main__":
    folder_path = "./dat"  # Ruta de la carpeta
    delimiter = " "  # Defineix el delimitador adequat
    process_all_files_in_folder(folder_path, delimiter)

############################EJERCICIO2 PASO 4 . 2########################################
import os
import pandas as pd

# Ruta a la carpeta que contiene los archivos .dat
carpeta = 'dat'

# Crear un DataFrame vac칤o para almacenar los datos de todas las estaciones
datos_totales = pd.DataFrame()

# Leer todos los archivos .dat en la carpeta
for archivo in os.listdir(carpeta):
    if archivo.endswith('.dat'):
        # Leer el archivo .dat
        ruta_archivo = os.path.join(carpeta, archivo)
        try:
            # Leer el archivo completo, ignorando las dos primeras l칤neas
            with open(ruta_archivo, 'r') as f:
                lineas = f.readlines()

                # Procesar solo las l칤neas relevantes (comenzando desde la l칤nea 2)
                for linea in lineas[2:]:
                    # Separar la l칤nea por espacios y filtrar valores v치lidos
                    valores = linea.split()
                    if len(valores) > 0 and valores[0] == 'P1':
                        # Extraer el a침o y los valores de precipitaci칩n
                        anio = int(valores[1])
                        precipitaciones = [float(v) for v in valores[2:] if v != '-999']  # Ignorar valores -999

                        # Sumar las precipitaciones del a침o
                        total_precipitacion = sum(precipitaciones)
                        # Crear un DataFrame temporal
                        df_temporal = pd.DataFrame({'A침o': [anio], 'Precipitaci칩n': [total_precipitacion]})

                        # Concatenar al DataFrame total
                        datos_totales = pd.concat([datos_totales, df_temporal], ignore_index=True)

        except Exception as e:
            print(f"Error al procesar {archivo}: {e}")

# Calcular precipitaciones totales y medias anuales
precipitacion_anual = datos_totales.groupby('A침o')['Precipitaci칩n'].agg(['sum', 'mean']).reset_index()
precipitacion_anual.columns = ['A침o', 'Total Precipitaci칩n (mm)', 'Media Precipitaci칩n (mm)']

# Filtrar por el rango de a침os deseado (2006 a 2100)
precipitacion_anual = precipitacion_anual[(precipitacion_anual['A침o'] >= 2006) & (precipitacion_anual['A침o'] <= 2100)]

# Redondear las columnas de precipitaci칩n a 2 decimales
precipitacion_anual['Total Precipitaci칩n (mm)'] = precipitacion_anual['Total Precipitaci칩n (mm)'].round(2)
precipitacion_anual['Media Precipitaci칩n (mm)'] = precipitacion_anual['Media Precipitaci칩n (mm)'].round(2)

# Mostrar total y media de precipitaciones
total_precipitacion = precipitacion_anual['Total Precipitaci칩n (mm)'].sum()
media_precipitacion = precipitacion_anual['Media Precipitaci칩n (mm)'].mean()
print("\n -------------Ejercicio 2 Paso 4.2-------------")
print("\n===== Total y Media de Precipitaciones =====")
print(f"Total de precipitaciones desde 2006 hasta 2100: {total_precipitacion:,.2f} mm")
print(f"Media de precipitaciones anuales desde 2006 hasta 2100: {media_precipitacion:,.2f} mm")

# Funci칩n para calcular extremos de precipitaci칩n
def anys_extrems(data):
    any_mes_plujos = data.loc[data['Total Precipitaci칩n (mm)'].idxmax()]
    any_mes_sec = data.loc[data['Total Precipitaci칩n (mm)'].idxmin()]

    print("\n===== Extrems de precipitaci칩 =====")
    print(f"游릱 Any m칠s pluj칩s: {any_mes_plujos['A침o']} amb {any_mes_plujos['Total Precipitaci칩n (mm)']} mm")
    print(f"游릳 Any m칠s sec: {any_mes_sec['A침o']} amb {any_mes_sec['Total Precipitaci칩n (mm)']} mm")
    return any_mes_plujos, any_mes_sec

# Funci칩n para calcular estad칤sticas adicionales
def estadistiques_addicionals(data):
    desviacio_estandard = data['Total Precipitaci칩n (mm)'].std()
    mediana = data['Total Precipitaci칩n (mm)'].median()
    print("\n===== Estad칤stiques addicionals =====")
    print(f"游늵 Desviaci칩 est맕dard de les precipitacions: {desviacio_estandard:.2f} mm")
    print(f"游늳 Mediana de les precipitacions anuals: {mediana:.2f} mm")
    return desviacio_estandard, mediana

# Calcular extremos y estad칤sticas
any_mes_plujos, any_mes_sec = anys_extrems(precipitacion_anual)
desviacio_estandard, mediana = estadistiques_addicionals(precipitacion_anual)

# Mostrar el total de precipitaciones en litros por cada dos a침os
print("\n===== Total de precipitaciones cada dos a침os (en litros) =====")
for i in range(0, len(precipitacion_anual), 2):
    if i + 1 < len(precipitacion_anual):  # Asegurarse de que hay un segundo a침o para sumar
        total_litros = (precipitacion_anual.iloc[i]['Total Precipitaci칩n (mm)'] +
                        precipitacion_anual.iloc[i + 1]['Total Precipitaci칩n (mm)']) * 1000  # mm a litros
        print(f"De {int(precipitacion_anual.iloc[i]['A침o'])} a {int(precipitacion_anual.iloc[i + 1]['A침o'])}: {total_litros:,.2f} litros")

# Mostrar resumen final
print("\n===== Resumen Final =====")
print(f"El any m칠s pluj칩s ser el {any_mes_plujos['A침o']} amb una precipitaci칩 de {any_mes_plujos['Total Precipitaci칩n (mm)']} mm.")
print(f"El any m칠s sec ser el {any_mes_sec['A침o']} amb una precipitaci칩 de {any_mes_sec['Total Precipitaci칩n (mm)']} mm.")

# Exportar res칰menes estad칤sticos a un archivo CSV
precipitacion_anual.to_csv('resumen_precipitacion.csv', index=False)
print("El resumen estad칤stico ha sido exportado a 'resumen_precipitacion.csv'")




########################## EJERCICIO 3 #############################
import os
import pandas as pd
import matplotlib.pyplot as plt

# Ruta a la carpeta que contiene los archivos .dat
carpeta = 'dat'

# Crear un DataFrame vac칤o para almacenar los datos de todas las estaciones
datos_totales = pd.DataFrame()

# Leer todos los archivos .dat en la carpeta
for archivo in os.listdir(carpeta):
    if archivo.endswith('.dat'):
        # Leer el archivo .dat
        ruta_archivo = os.path.join(carpeta, archivo)
        try:
            # Leer el archivo completo, ignorando las dos primeras l칤neas
            with open(ruta_archivo, 'r') as f:
                lineas = f.readlines()

                # Procesar solo las l칤neas relevantes (comenzando desde la l칤nea 2)
                for linea in lineas[2:]:
                    # Separar la l칤nea por espacios y filtrar valores v치lidos
                    valores = linea.split()
                    if len(valores) > 0 and valores[0] == 'P1':
                        # Extraer el a침o y los valores de precipitaci칩n
                        anio = int(float(valores[1]))  # Asegurarse de que el a침o sea un entero
                        precipitaciones = [float(v) for v in valores[2:] if v != '-999']  # Ignorar valores -999

                        # Sumar las precipitaciones del a침o
                        total_precipitacion = sum(precipitaciones)
                        # Crear un DataFrame temporal
                        df_temporal = pd.DataFrame({'A침o': [anio], 'Precipitaci칩n': [total_precipitacion]})

                        # Concatenar al DataFrame total
                        datos_totales = pd.concat([datos_totales, df_temporal], ignore_index=True)

        except Exception as e:
            print(f"Error al procesar {archivo}: {e}")

# Calcular precipitaciones totales y medias anuales
precipitacion_anual = datos_totales.groupby('A침o')['Precipitaci칩n'].agg(['sum', 'mean']).reset_index()
precipitacion_anual.columns = ['A침o', 'Total Precipitaci칩n (mm)', 'Media Precipitaci칩n (mm)']

# Filtrar por el rango de a침os deseado (2006 a 2100)
precipitacion_anual = precipitacion_anual[(precipitacion_anual['A침o'] >= 2006) & (precipitacion_anual['A침o'] <= 2100)]

# Asegurarse de que la columna "A침o" sea de tipo entero
precipitacion_anual['A침o'] = precipitacion_anual['A침o'].astype(int)

# Exportar res칰menes estad칤sticos a un archivo CSV
precipitacion_anual.to_csv('resumen_precipitacion.csv', index=False)

# Generar el gr치fico de barras
plt.figure(figsize=(14, 7))
plt.bar(precipitacion_anual['A침o'], precipitacion_anual['Total Precipitaci칩n (mm)'], color='skyblue')
plt.title('Precipitaci칩n Anual (2006-2100)')
plt.xlabel('A침o')
plt.ylabel('Precipitaci칩n Total (mm)')

# Establecer las etiquetas del eje X para que muestren todos los a침os
plt.xticks(precipitacion_anual['A침o'], rotation=90)  # Rotaci칩n de 90 grados para mejor legibilidad

plt.grid(axis='y', linestyle='--', alpha=0.7)  # A침adir l칤neas de cuadr칤cula en el eje Y
plt.tight_layout()  # Ajustar el layout para que no se solapen las etiquetas

# A침adir print para indicar que se est치 abriendo el gr치fico
print("\n -------------Ejercicio 3-------------")
print("Abriendo gr치fico...")

plt.show()

# Obtener el a침o m치s pluvioso y m치s seco
anio_max_precip = precipitacion_anual.loc[precipitacion_anual['Total Precipitaci칩n (mm)'].idxmax()]
anio_min_precip = precipitacion_anual.loc[precipitacion_anual['Total Precipitaci칩n (mm)'].idxmin()]

# Mostrar el resumen final con a침os como enteros
print(f"\n===== Resumen Final =====")
print(f"El a침o m치s pluvioso ser치 el {anio_max_precip['A침o']} con una precipitaci칩n de {anio_max_precip['Total Precipitaci칩n (mm)']} mm.")
print(f"El a침o m치s seco ser치 el {anio_min_precip['A침o']} con una precipitaci칩n de {anio_min_precip['Total Precipitaci칩n (mm)']} mm.")
print("El resumen estad칤stico ha sido exportado a 'resumen_precipitacion.csv'")



